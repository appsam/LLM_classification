{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O9F0qRsaKTje"
      },
      "outputs": [],
      "source": [
        "# 데이터 처리 및 기본 라이브러리\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "tqdm.pandas() # pandas apply에 진행 상황 표시를 위함\n",
        "\n",
        "# 머신러닝 모델 및 검증 도구\n",
        "import lightgbm as lgbm\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# TF-IDF 및 차원 축소\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# 딥러닝(임베딩, PPL) 모델\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModel, AutoModelForCausalLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_qiIAUFnKTjf"
      },
      "outputs": [],
      "source": [
        "train = pd.read_csv('train.csv', encoding='utf-8-sig')\n",
        "test = pd.read_csv('test.csv', encoding='utf-8-sig')\n",
        "sample_submission = pd.read_csv('sample_submission.csv', encoding='utf-8-sig')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GYdy0Nl-7eKr",
        "outputId": "c58bf33d-4fdd-40c5-8331-d66b75ec7e70"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n",
            "\n",
            "[훈련 데이터] 특징 생성 시작...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "BERT Embedding: 100%|██████████| 760/760 [00:41<00:00, 18.21it/s]\n",
            "BERT Embedding: 100%|██████████| 760/760 [24:11<00:00,  1.91s/it]\n",
            "Train PPL:   0%|          | 0/97172 [00:00<?, ?it/s]`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.\n",
            "Train PPL: 100%|██████████| 97172/97172 [1:51:07<00:00, 14.57it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[테스트 데이터] 특징 생성 시작 (문단 단위)...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "BERT Embedding: 100%|██████████| 16/16 [00:00<00:00, 16.60it/s]\n",
            "BERT Embedding: 100%|██████████| 16/16 [00:20<00:00,  1.31s/it]\n",
            "Test PPL: 100%|██████████| 1962/1962 [00:22<00:00, 87.12it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "생성된 최종 특징 벡터들을 파일로 저장합니다...\n",
            "저장 완료!\n"
          ]
        }
      ],
      "source": [
        "# =======================================================================================\n",
        "# === 이 셀은 시간이 매우 오래 걸립니다. 처음 한 번만 실행하여 특징을 저장하세요. ===\n",
        "# =======================================================================================\n",
        "\n",
        "# GPU 사용 설정\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# --- 모델 및 토크나이저 로드 ---\n",
        "bert_tokenizer = AutoTokenizer.from_pretrained('klue/bert-base')\n",
        "bert_model = AutoModel.from_pretrained('klue/bert-base').to(device)\n",
        "ppl_tokenizer = AutoTokenizer.from_pretrained(\"skt/kogpt2-base-v2\")\n",
        "ppl_model = AutoModelForCausalLM.from_pretrained(\"skt/kogpt2-base-v2\").to(device)\n",
        "\n",
        "# --- 특징 생성 함수 정의 ---\n",
        "def get_bert_embeddings(texts, batch_size=128):\n",
        "    all_embeddings = []\n",
        "    for i in tqdm(range(0, len(texts), batch_size), desc=\"BERT Embedding\"):\n",
        "        batch = texts[i:i+batch_size]\n",
        "        batch_dict = bert_tokenizer(batch, max_length=512, padding=True, truncation=True, return_tensors='pt').to(device)\n",
        "        with torch.no_grad():\n",
        "            outputs = bert_model(**batch_dict)\n",
        "        embeddings = outputs.pooler_output\n",
        "        all_embeddings.append(embeddings.cpu().numpy())\n",
        "    return np.vstack(all_embeddings)\n",
        "\n",
        "def get_perplexity(text):\n",
        "    encodings = ppl_tokenizer(text, return_tensors=\"pt\")\n",
        "    max_length = ppl_model.config.max_position_embeddings\n",
        "    stride = 512\n",
        "    nlls = []\n",
        "    for i in range(0, encodings.input_ids.size(1), stride):\n",
        "        begin_loc, end_loc = max(i + stride - max_length, 0), min(i + stride, encodings.input_ids.size(1))\n",
        "        trg_len = end_loc - i\n",
        "        input_ids = encodings.input_ids[:, begin_loc:end_loc].to(device)\n",
        "        target_ids = input_ids.clone()\n",
        "        target_ids[:, :-trg_len] = -100\n",
        "        with torch.no_grad():\n",
        "            outputs = ppl_model(input_ids, labels=target_ids)\n",
        "            neg_log_likelihood = outputs.loss * trg_len\n",
        "        nlls.append(neg_log_likelihood)\n",
        "    return torch.exp(torch.stack(nlls).sum() / end_loc).item()\n",
        "\n",
        "# --- 훈련 데이터 특징 생성 ---\n",
        "print(\"\\n[훈련 데이터] 특징 생성 시작...\")\n",
        "X_train_title_emb = get_bert_embeddings(train['title'].tolist())\n",
        "X_train_text_emb = get_bert_embeddings(train['full_text'].tolist())\n",
        "X_train_embedding = np.concatenate([X_train_title_emb, X_train_text_emb], axis=1)\n",
        "\n",
        "tqdm.pandas(desc=\"Train PPL\")\n",
        "train['ppl_full_text'] = train['full_text'].progress_apply(get_perplexity)\n",
        "X_train_ppl = train[['ppl_full_text']].values\n",
        "\n",
        "svd = TruncatedSVD(n_components=128, random_state=42)\n",
        "tfidf = TfidfVectorizer(ngram_range=(1, 2), max_features=10000)\n",
        "tfidf_pipeline = Pipeline([('tfidf', tfidf), ('svd', svd)])\n",
        "X_train_tfidf = tfidf_pipeline.fit_transform(train['full_text'])\n",
        "\n",
        "##정규화 진행하기 !!\n",
        "\n",
        "X = np.concatenate([X_train_embedding, X_train_ppl, X_train_tfidf], axis=1)\n",
        "y = train['generated'].values\n",
        "\n",
        "# --- 테스트 데이터 특징 생성 (문단 단위) ---\n",
        "print(\"\\n[테스트 데이터] 특징 생성 시작 (문단 단위)...\")\n",
        "test = test.rename(columns={'paragraph_text': 'full_text'})\n",
        "\n",
        "X_test_title_emb = get_bert_embeddings(test['title'].tolist())\n",
        "X_test_text_emb = get_bert_embeddings(test['full_text'].tolist())\n",
        "X_test_embedding = np.concatenate([X_test_title_emb, X_test_text_emb], axis=1)\n",
        "\n",
        "tqdm.pandas(desc=\"Test PPL\")\n",
        "test['ppl_full_text'] = test['full_text'].progress_apply(get_perplexity)\n",
        "X_test_ppl = test[['ppl_full_text']].values\n",
        "\n",
        "X_test_tfidf = tfidf_pipeline.transform(test['full_text'])\n",
        "\n",
        "X_test = np.concatenate([X_test_embedding, X_test_ppl, X_test_tfidf], axis=1)\n",
        "\n",
        "# --- 파일 저장 ---\n",
        "print(\"\\n생성된 최종 특징 벡터들을 파일로 저장합니다...\")\n",
        "np.save('X_final_features.npy', X)\n",
        "np.save('y_final_labels.npy', y)\n",
        "np.save('X_test_final_paragraph.npy', X_test) # 문단 단위 테스트 특징 저장\n",
        "print(\"저장 완료!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jUsjESSq7z1L",
        "outputId": "bebc75e8-d347-4b8b-8f76-1c30b747f16a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "저장된 특징 벡터를 성공적으로 불러왔습니다.\n",
            "훈련 데이터 특징 벡터 모양: (97172, 1665)\n",
            "테스트 데이터 특징 벡터 모양: (1962, 1665)\n"
          ]
        }
      ],
      "source": [
        "# =======================================================================================\n",
        "# === 위 [Cell 3]에서 임베딩을 저장한 후, 다음부터는 이 셀만 실행하여 특징을 불러오세요. ===\n",
        "# =======================================================================================\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# 저장된 파일 불러오기\n",
        "X = np.load('X_final_features.npy')\n",
        "y = np.load('y_final_labels.npy')\n",
        "X_test = np.load('X_test_final_paragraph.npy')\n",
        "\n",
        "print(\"저장된 특징 벡터를 성공적으로 불러왔습니다.\")\n",
        "print(\"훈련 데이터 특징 벡터 모양:\", X.shape)\n",
        "print(\"테스트 데이터 특징 벡터 모양:\", X_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sX4S7x3YHPSG",
        "outputId": "d1b7c0b0-e4c1-498f-b142-c0969c8f1673"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "===== Fold 1 시작 =====\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "===== Fold 2 시작 =====\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "===== Fold 3 시작 =====\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "===== Fold 4 시작 =====\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "===== Fold 5 시작 =====\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "최적 파라미터를 적용한 최종 OOF AUC: 0.91576\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import lightgbm as lgbm\n",
        "\n",
        "# 이전에 Optuna로 직접 찾으신 최적의 하이퍼파라미터\n",
        "best_params = {\n",
        "    'learning_rate': 0.04312040147756817,\n",
        "    'num_leaves': 41,\n",
        "    'max_depth': 6,\n",
        "    'subsample': 0.6968567940207964,\n",
        "    'colsample_bytree': 0.8428253384396042,\n",
        "    'lambda_l1': 9.288489210313957e-06,\n",
        "    'lambda_l2': 0.0021254726288526147\n",
        "}\n",
        "\n",
        "# 고정 파라미터 추가\n",
        "best_params['objective'] = 'binary'\n",
        "best_params['metric'] = 'auc'\n",
        "best_params['verbosity'] = -1\n",
        "best_params['boosting_type'] = 'gbdt'\n",
        "best_params['random_state'] = 42\n",
        "best_params['n_estimators'] = 1000\n",
        "best_params['device'] = 'gpu'\n",
        "\n",
        "# --- K-Fold 교차 검증 시작 ---\n",
        "N_SPLITS = 5\n",
        "skf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=42)\n",
        "\n",
        "models = []\n",
        "oof_preds = np.zeros(len(X))\n",
        "\n",
        "for fold, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n",
        "    print(f\"===== Fold {fold+1} 시작 =====\")\n",
        "    X_train, y_train = X[train_idx], y[train_idx]\n",
        "    X_val, y_val = X[val_idx], y[val_idx]\n",
        "\n",
        "    # 위에서 정의한 best_params로 모델 학습\n",
        "    model = lgbm.LGBMClassifier(**best_params)\n",
        "    model.fit(X_train, y_train,\n",
        "            eval_set=[(X_val, y_val)],\n",
        "            eval_metric='auc',\n",
        "            callbacks=[lgbm.early_stopping(100, verbose=False)])\n",
        "\n",
        "    val_preds = model.predict_proba(X_val)[:, 1]\n",
        "    oof_preds[val_idx] = val_preds\n",
        "    models.append(model)\n",
        "\n",
        "oof_auc = roc_auc_score(y, oof_preds)\n",
        "print(f\"\\n최적 파라미터를 적용한 최종 OOF AUC: {oof_auc:.5f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NX68Nq3GHTsS",
        "outputId": "f1d64af2-a297-4dd9-aa4d-e282be50a5cd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# K-Fold로 학습된 모든 모델의 예측을 평균(앙상블)\n",
        "test_preds_list = [model.predict_proba(X_test)[:, 1] for model in models]\n",
        "test_preds_ensembled = np.mean(test_preds_list, axis=0)\n",
        "\n",
        "# 예측 결과가 이미 문단 순서와 동일하므로 바로 할당\n",
        "sample_submission['generated'] = test_preds_ensembled\n",
        "\n",
        "# 제출 파일 생성\n",
        "sample_submission.to_csv('submission_bert_lightgbm.csv', index=False)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
