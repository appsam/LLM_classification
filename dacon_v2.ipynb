{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46af6247-a32f-4c09-8c63-92c346902d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 데이터 처리 및 기본 라이브러리 ===\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "import gc\n",
    "\n",
    "# === 머신러닝 모델 및 검증 도구 ===\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# === 이상치 탐지 ===\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "\n",
    "# === 특징 추출(Feature Engineering) 도구 ===\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# === 딥러닝(임베딩, PPL) 모델 ===\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "# === 병렬 처리를 위한 라이브러리 ===\n",
    "from joblib import Parallel, delayed\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157047c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- GPU 설정 및 최적화 ---\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# TF32 최적화 활성화\n",
    "if torch.cuda.is_available():\n",
    "    torch.backends.cuda.matmul.allow_tf32 = True\n",
    "    torch.backends.cudnn.allow_tf32 = True\n",
    "    print(\"TF32 최적화 활성화됨\")\n",
    "\n",
    "def print_gpu_utilization():\n",
    "    \"\"\"GPU 메모리 사용량 모니터링\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        allocated = torch.cuda.memory_allocated() / 1024**3\n",
    "        reserved = torch.cuda.memory_reserved() / 1024**3\n",
    "        max_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3\n",
    "        print(f\"GPU 메모리 사용량: {allocated:.2f} GB\")\n",
    "        print(f\"GPU 메모리 캐시: {reserved:.2f} GB\")\n",
    "        print(f\"GPU 메모리 사용률: {allocated/max_memory*100:.1f}%\")\n",
    "        print(f\"총 GPU 메모리: {max_memory:.2f} GB\")\n",
    "\n",
    "# --- 데이터 로드 ---\n",
    "print(\"데이터를 로드합니다...\")\n",
    "train_df_original = pd.read_csv('data/train.csv', encoding='utf-8-sig')\n",
    "test_df = pd.read_csv('data/test.csv', encoding='utf-8-sig')\n",
    "sample_submission = pd.read_csv('data/sample_submission.csv', encoding='utf-8-sig')\n",
    "print(\"데이터 로드 완료.\")\n",
    "\n",
    "# # --- 딥러닝 모델 로드 (Mixed Precision 적용) ---\n",
    "# print(\"딥러닝 모델들을 로드합니다...\")\n",
    "# bert_tokenizer = AutoTokenizer.from_pretrained('klue/bert-base')\n",
    "# bert_model = AutoModel.from_pretrained('klue/bert-base').half().to(device)  # FP16 적용\n",
    "# print(\"모델 로드 완료.\")\n",
    "# print_gpu_utilization()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a4bb0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_paragraph_df 재생성 (이상탐지 및 레이블에 필요)\n",
    "print(\"📝 훈련 데이터 문단 분리 중...\")\n",
    "train_df_original['paragraphs'] = train_df_original['full_text'].str.split('\\n')\n",
    "train_paragraph_df = train_df_original.explode('paragraphs').rename(columns={'paragraphs': 'text'})\n",
    "train_paragraph_df = train_paragraph_df.dropna(subset=['text'])\n",
    "train_paragraph_df = train_paragraph_df[train_paragraph_df['text'].str.strip().astype(bool)].reset_index(drop=True)\n",
    "\n",
    "print(f\"✅ 문단 분리 완료: {len(train_paragraph_df):,}개\")\n",
    "print(f\"사람 글: {(train_paragraph_df['generated'] == 0).sum():,}개\")\n",
    "print(f\"AI 글: {(train_paragraph_df['generated'] == 1).sum():,}개\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53daad8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 최적화된 특징 생성 함수 ---\n",
    "def get_bert_embeddings_optimized(texts, batch_size=512):\n",
    "    \"\"\"\n",
    "    A100 GPU 최적화된 BERT 임베딩 생성 함수\n",
    "    - Mixed Precision (FP16) 적용\n",
    "    - 대용량 배치 사이즈\n",
    "    - 메모리 관리 최적화\n",
    "    \"\"\"\n",
    "    all_embeddings = []\n",
    "\n",
    "    # 메모리 사전 정리\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "    print(f\"배치 크기: {batch_size}, 총 텍스트 수: {len(texts)}\")\n",
    "\n",
    "    for i in tqdm(range(0, len(texts), batch_size), desc=\"BERT Embedding (최적화됨)\"):\n",
    "        try:\n",
    "            batch = [str(t) for t in texts[i:i+batch_size]]\n",
    "\n",
    "            # 토크나이징\n",
    "            batch_dict = bert_tokenizer(\n",
    "                batch,\n",
    "                max_length=512,\n",
    "                padding=True,\n",
    "                truncation=True,\n",
    "                return_tensors='pt'\n",
    "            ).to(device)\n",
    "\n",
    "            # Mixed Precision으로 Forward Pass\n",
    "            with torch.no_grad():\n",
    "                with torch.cuda.amp.autocast():\n",
    "                    outputs = bert_model(**batch_dict)\n",
    "\n",
    "            # 임베딩 추출 (float32로 변환하여 정확도 유지)\n",
    "            embeddings = outputs.pooler_output.float()\n",
    "            all_embeddings.append(embeddings.cpu().numpy())\n",
    "\n",
    "            # 즉시 메모리 해제\n",
    "            del batch_dict, outputs, embeddings\n",
    "\n",
    "            # 주기적 메모리 정리 (10배치마다)\n",
    "            if i % (10 * batch_size) == 0:\n",
    "                torch.cuda.empty_cache()\n",
    "                gc.collect()\n",
    "\n",
    "        except RuntimeError as e:\n",
    "            if \"out of memory\" in str(e):\n",
    "                print(f\"\\n메모리 부족 발생! 배치 크기를 {batch_size//2}로 줄입니다.\")\n",
    "                torch.cuda.empty_cache()\n",
    "                gc.collect()\n",
    "                return get_bert_embeddings_optimized(texts, batch_size//2)\n",
    "            else:\n",
    "                raise e\n",
    "\n",
    "    # 최종 메모리 정리\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "    return np.vstack(all_embeddings)\n",
    "\n",
    "def find_optimal_batch_size(sample_texts, start_batch=512, max_batch=2048):\n",
    "    \"\"\"최적 배치 크기 자동 탐색\"\"\"\n",
    "    print(\"최적 배치 크기를 탐색합니다...\")\n",
    "\n",
    "    for batch_size in [start_batch, start_batch*2, max_batch]:\n",
    "        try:\n",
    "            print(f\"배치 크기 {batch_size} 테스트 중...\")\n",
    "            # 소량 데이터로 테스트\n",
    "            test_sample = sample_texts[:min(batch_size*2, len(sample_texts))]\n",
    "            _ = get_bert_embeddings_optimized(test_sample, batch_size=batch_size)\n",
    "            print(f\"배치 크기 {batch_size} 성공!\")\n",
    "            optimal_batch = batch_size\n",
    "        except RuntimeError as e:\n",
    "            if \"out of memory\" in str(e):\n",
    "                print(f\"배치 크기 {batch_size} 메모리 부족\")\n",
    "                break\n",
    "            else:\n",
    "                raise e\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    return optimal_batch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16eafe49",
   "metadata": {},
   "source": [
    "# 훈련 데이터 임베딩 + TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d30da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # --- 2. 최적 배치 크기 찾기 ---\n",
    "# sample_texts = train_paragraph_df['text'].head(1000).tolist()\n",
    "# optimal_batch_size = find_optimal_batch_size(sample_texts)\n",
    "# print(f\"최적 배치 크기: {optimal_batch_size}\")\n",
    "\n",
    "# # --- 3. 훈련 데이터 모든 문단에 대한 특징 생성 (최적화됨) ---\n",
    "# print(f\"\\n[훈련 문단 데이터] 특징 생성 시작... (배치 크기: {optimal_batch_size})\")\n",
    "\n",
    "# # 3-1. BERT 임베딩 (제목)\n",
    "# print(\"제목 BERT 임베딩 생성 중...\")\n",
    "# print_gpu_utilization()\n",
    "# title_embeddings = get_bert_embeddings_optimized(\n",
    "#     train_paragraph_df['title'].tolist(),\n",
    "#     batch_size=optimal_batch_size\n",
    "# )\n",
    "# print(\"제목 임베딩 완료!\")\n",
    "# print_gpu_utilization()\n",
    "\n",
    "# # 3-2. BERT 임베딩 (본문)\n",
    "# print(\"본문 BERT 임베딩 생성 중...\")\n",
    "# text_embeddings = get_bert_embeddings_optimized(\n",
    "#     train_paragraph_df['text'].tolist(),\n",
    "#     batch_size=optimal_batch_size\n",
    "# )\n",
    "# print(\"본문 임베딩 완료!\")\n",
    "# print_gpu_utilization()\n",
    "\n",
    "# # 3-3. BERT 임베딩 결합\n",
    "# X_train_p_emb = np.concatenate([title_embeddings, text_embeddings], axis=1)\n",
    "# print(f\"결합된 BERT 임베딩 shape: {X_train_p_emb.shape}\")\n",
    "\n",
    "# # 메모리 정리\n",
    "# del title_embeddings, text_embeddings\n",
    "# gc.collect()\n",
    "\n",
    "# print(\"TF-IDF + SVD 특징 생성 중...\")\n",
    "# tfidf_pipeline = Pipeline([\n",
    "#     ('tfidf', TfidfVectorizer(ngram_range=(1, 2), max_features=10000)),\n",
    "#     ('svd', TruncatedSVD(n_components=128, random_state=42))\n",
    "# ])\n",
    "# X_train_p_tfidf = tfidf_pipeline.fit_transform(train_paragraph_df['text'])\n",
    "# print(f\"TF-IDF + SVD shape: {X_train_p_tfidf.shape}\")\n",
    "\n",
    "# # 3-5. 모든 특징 결합\n",
    "# print(\"모든 특징을 결합합니다...\")\n",
    "# X_train_paragraph_features = np.concatenate([X_train_p_emb, X_train_p_tfidf], axis=1)\n",
    "# print(f\"최종 특징 행렬 shape: {X_train_paragraph_features.shape}\")\n",
    "\n",
    "# # --- 4. 결과 저장 ---\n",
    "# print(\"특징 행렬을 저장합니다...\")\n",
    "# np.save('X_train_paragraph_features.npy', X_train_paragraph_features)\n",
    "# print(\"저장 완료!\")\n",
    "\n",
    "# # --- 5. 최종 GPU 메모리 상태 ---\n",
    "# print(\"\\n=== 최종 GPU 메모리 상태 ===\")\n",
    "# print_gpu_utilization()\n",
    "\n",
    "# # 메모리 정리\n",
    "# torch.cuda.empty_cache()\n",
    "# gc.collect()\n",
    "# print(\"메모리 정리 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665b7355",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 컬럼명 확인 및 변환 (필요시)\n",
    "# if 'paragraph_text' in test_df.columns:\n",
    "#     test_df = test_df.rename(columns={'paragraph_text': 'text'})\n",
    "#     print(\"컬럼명 변환: paragraph_text → text\")\n",
    "\n",
    "# print(f\"테스트 데이터 shape: {test_df.shape}\")\n",
    "# print(f\"테스트 데이터 컬럼: {list(test_df.columns)}\")\n",
    "\n",
    "# # --- 2. 최적 배치 크기 찾기 (테스트 데이터 기준) ---\n",
    "# sample_test_texts = test_df['text'].head(1000).tolist()\n",
    "# optimal_batch_size = find_optimal_batch_size(sample_test_texts)\n",
    "# print(f\"테스트 데이터 최적 배치 크기: {optimal_batch_size}\")\n",
    "\n",
    "# # --- 3. 테스트 데이터 특징 생성 (최적화됨) ---\n",
    "# print(f\"\\n[테스트 데이터] 특징 생성 시작... (배치 크기: {optimal_batch_size})\")\n",
    "\n",
    "# # 3-1. BERT 임베딩 (제목)\n",
    "# print(\"테스트 데이터 제목 BERT 임베딩 생성 중...\")\n",
    "# print_gpu_utilization()\n",
    "# test_title_embeddings = get_bert_embeddings_optimized(\n",
    "#     test_df['title'].tolist(),\n",
    "#     batch_size=optimal_batch_size\n",
    "# )\n",
    "# print(\"테스트 제목 임베딩 완료!\")\n",
    "# print_gpu_utilization()\n",
    "\n",
    "# # 3-2. BERT 임베딩 (본문)\n",
    "# print(\"테스트 데이터 본문 BERT 임베딩 생성 중...\")\n",
    "# test_text_embeddings = get_bert_embeddings_optimized(\n",
    "#     test_df['text'].tolist(),\n",
    "#     batch_size=optimal_batch_size\n",
    "# )\n",
    "# print(\"테스트 본문 임베딩 완료!\")\n",
    "# print_gpu_utilization()\n",
    "\n",
    "# # 3-3. BERT 임베딩 결합\n",
    "# X_test_p_emb = np.concatenate([test_title_embeddings, test_text_embeddings], axis=1)\n",
    "# print(f\"테스트 결합된 BERT 임베딩 shape: {X_test_p_emb.shape}\")\n",
    "\n",
    "# # 메모리 정리\n",
    "# del test_title_embeddings, test_text_embeddings\n",
    "# gc.collect()\n",
    "\n",
    "# # --- 3-4. TF-IDF + SVD 처리 ---\n",
    "# print(\"테스트 데이터에 TF-IDF transform 적용...\")\n",
    "# X_test_p_tfidf = tfidf_pipeline.transform(test_df['text'])\n",
    "# print(f\"테스트 TF-IDF + SVD shape: {X_test_p_tfidf.shape}\")\n",
    "\n",
    "# # --- 3-5. 모든 특징 결합 ---\n",
    "# print(\"테스트 데이터의 모든 특징을 결합합니다...\")\n",
    "# X_test_paragraph_features = np.concatenate([X_test_p_emb, X_test_p_tfidf], axis=1)\n",
    "# print(f\"테스트 최종 특징 행렬 shape: {X_test_paragraph_features.shape}\")\n",
    "\n",
    "# # --- 4. 결과 저장 ---\n",
    "# print(\"\\n테스트 특징 행렬을 저장합니다...\")\n",
    "# np.save('X_test_paragraph_features.npy', X_test_paragraph_features)\n",
    "# print(\"✅ X_test_paragraph_features.npy 저장 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "load-train-npy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 훈련 특징 로드 완료: (1226364, 1664)\n"
     ]
    }
   ],
   "source": [
    "# --- 미리 생성된 특징(.npy) 파일 로드 ---\n",
    "print(\"💾 미리 생성된 훈련 데이터 특징 파일을 로드합니다...\")\n",
    "\n",
    "# data 폴더에 저장된 .npy 파일 경로를 사용합니다.\n",
    "X_train_paragraph_features = np.load('data/X_train_paragraph_features.npy')\n",
    "\n",
    "print(f\"✅ 훈련 특징 로드 완료: {X_train_paragraph_features.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f8fe0882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 하이브리드 이상탐지 시작\n",
      "사람 글 문단: 1,125,652개\n",
      "  1단계: Isolation Forest...\n",
      "  1차 필터링: 956,804개 남음\n",
      "  2단계: LOF...\n",
      "✅ 하이브리드 이상탐지 완료! (12734.1초)\n",
      "  제거된 노이즈: 216,689개 (19.3%)\n",
      "  정제된 사람 글: 908,963개\n",
      "\n",
      "📊 정제된 훈련 데이터: (1009675, 1664)\n",
      "  정제된 사람 글: 908,963개\n",
      "  AI 글: 100,712개\n"
     ]
    }
   ],
   "source": [
    "print(\"🔍 하이브리드 이상탐지 시작\")\n",
    "start_time = time.time()\n",
    "\n",
    "# 사람 글 인덱스 추출 (라벨 0)\n",
    "human_indices = np.where(train_paragraph_df['generated'] == 0)[0]\n",
    "print(f\"사람 글 문단: {len(human_indices):,}개\")\n",
    "\n",
    "# 1단계: Isolation Forest (빠른 1차 필터링)\n",
    "print(\"  1단계: Isolation Forest...\")\n",
    "iso_forest = IsolationForest(\n",
    "    contamination=0.15,       # 15% 이상치 가정\n",
    "    n_estimators=200,\n",
    "    max_samples='auto',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "iso_outliers = iso_forest.fit_predict(X_train_paragraph_features[human_indices])\n",
    "stage1_clean = human_indices[iso_outliers == 1]\n",
    "print(f\"  1차 필터링: {len(stage1_clean):,}개 남음\")\n",
    "\n",
    "# 2단계: LOF (정교한 2차 필터링)\n",
    "print(\"  2단계: LOF...\")\n",
    "lof = LocalOutlierFactor(\n",
    "    n_neighbors=min(50, len(stage1_clean) // 20),\n",
    "    contamination=0.05,       # 5% 추가 제거\n",
    "    algorithm='auto',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "lof_outliers = lof.fit_predict(X_train_paragraph_features[stage1_clean])\n",
    "final_clean_indices = stage1_clean[lof_outliers == 1]\n",
    "\n",
    "elapsed = time.time() - start_time\n",
    "removed = len(human_indices) - len(final_clean_indices)\n",
    "\n",
    "print(f\"✅ 하이브리드 이상탐지 완료! ({elapsed:.1f}초)\")\n",
    "print(f\"  제거된 노이즈: {removed:,}개 ({removed/len(human_indices)*100:.1f}%)\")\n",
    "print(f\"  정제된 사람 글: {len(final_clean_indices):,}개\")\n",
    "\n",
    "# 정제된 훈련 데이터 구성\n",
    "# 정제된 사람 글 + 모든 AI 글\n",
    "ai_indices = np.where(train_paragraph_df['generated'] == 1)[0]\n",
    "clean_indices = np.concatenate([final_clean_indices, ai_indices])\n",
    "\n",
    "X_train_clean = X_train_paragraph_features[clean_indices]\n",
    "y_train_clean = train_paragraph_df['generated'].iloc[clean_indices].values\n",
    "\n",
    "print(f\"\\n📊 정제된 훈련 데이터: {X_train_clean.shape}\")\n",
    "print(f\"  정제된 사람 글: {(y_train_clean == 0).sum():,}개\")\n",
    "print(f\"  AI 글: {(y_train_clean == 1).sum():,}개\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d9917074",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>full_text</th>\n",
       "      <th>generated</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>카호올라웨섬</td>\n",
       "      <td>카호올라웨섬은 하와이 제도를 구성하는 8개의 화산섬 가운데 하나로 면적은 115.5...</td>\n",
       "      <td>0</td>\n",
       "      <td>카호올라웨섬은 하와이 제도를 구성하는 8개의 화산섬 가운데 하나로 면적은 115.5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>카호올라웨섬</td>\n",
       "      <td>카호올라웨섬은 하와이 제도를 구성하는 8개의 화산섬 가운데 하나로 면적은 115.5...</td>\n",
       "      <td>0</td>\n",
       "      <td>마우이섬에서 남서쪽으로 약 11km 정도 떨어진 곳에 위치하며 라나이섬의 남동쪽에...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>카호올라웨섬</td>\n",
       "      <td>카호올라웨섬은 하와이 제도를 구성하는 8개의 화산섬 가운데 하나로 면적은 115.5...</td>\n",
       "      <td>0</td>\n",
       "      <td>1000년경부터 사람이 거주했으며 해안 지대에는 소규모 임시 어촌이 형성되었다. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>카호올라웨섬</td>\n",
       "      <td>카호올라웨섬은 하와이 제도를 구성하는 8개의 화산섬 가운데 하나로 면적은 115.5...</td>\n",
       "      <td>0</td>\n",
       "      <td>1830년대에는 하와이 왕국의 카메하메하 3세 국왕에 의해 남자 죄수들의 유형지로...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>카호올라웨섬</td>\n",
       "      <td>카호올라웨섬은 하와이 제도를 구성하는 8개의 화산섬 가운데 하나로 면적은 115.5...</td>\n",
       "      <td>0</td>\n",
       "      <td>1910년부터 1918년까지 하와이 준주가 섬의 원래 모습을 복원하기 위해 이 섬...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>카호올라웨섬</td>\n",
       "      <td>카호올라웨섬은 하와이 제도를 구성하는 8개의 화산섬 가운데 하나로 면적은 115.5...</td>\n",
       "      <td>0</td>\n",
       "      <td>1941년 12월 7일에 일어난 일본 제국 해군의 진주만 공격을 계기로 카호올라웨...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>청색거성</td>\n",
       "      <td>천문학에서 청색거성(靑色巨星, )은 광도 분류에서 III형(거성) 또는 II형(밝은...</td>\n",
       "      <td>0</td>\n",
       "      <td>천문학에서 청색거성(靑色巨星, )은 광도 분류에서 III형(거성) 또는 II형(밝은...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>청색거성</td>\n",
       "      <td>천문학에서 청색거성(靑色巨星, )은 광도 분류에서 III형(거성) 또는 II형(밝은...</td>\n",
       "      <td>0</td>\n",
       "      <td>용어는 각자 다른 진화 단계에 있는 여러 가지 별에 적용되는데, 이들 모두 주계열...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>청색거성</td>\n",
       "      <td>천문학에서 청색거성(靑色巨星, )은 광도 분류에서 III형(거성) 또는 II형(밝은...</td>\n",
       "      <td>0</td>\n",
       "      <td>청색거성이라는 명칭은 종종 매우 크고 뜨거운 주계열성과 같이, 다른 무겁고 밝은 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>청색거성</td>\n",
       "      <td>천문학에서 청색거성(靑色巨星, )은 광도 분류에서 III형(거성) 또는 II형(밝은...</td>\n",
       "      <td>0</td>\n",
       "      <td>청색거성은 엄격히 정의된 단어가 아니어서 서로 다른 다양한 유형의 별에 폭넓게 사...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>청색거성</td>\n",
       "      <td>천문학에서 청색거성(靑色巨星, )은 광도 분류에서 III형(거성) 또는 II형(밝은...</td>\n",
       "      <td>0</td>\n",
       "      <td>청색거성으로 표현되는 매우 차갑고 어두운 별은, 적색거성 단계를 지난 중간 질량의...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>청색거성</td>\n",
       "      <td>천문학에서 청색거성(靑色巨星, )은 광도 분류에서 III형(거성) 또는 II형(밝은...</td>\n",
       "      <td>0</td>\n",
       "      <td>거성에 대해서 명확한 최대 한계는 없지만, O형 초반의 주계열성과 그와 거의 동일...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>청색거성</td>\n",
       "      <td>천문학에서 청색거성(靑色巨星, )은 광도 분류에서 III형(거성) 또는 II형(밝은...</td>\n",
       "      <td>0</td>\n",
       "      <td>HR 도표의 청색거성 영역에서 발견되는 별은 일생에서의 단계가 각자 크게 다를 수...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>청색거성</td>\n",
       "      <td>천문학에서 청색거성(靑色巨星, )은 광도 분류에서 III형(거성) 또는 II형(밝은...</td>\n",
       "      <td>0</td>\n",
       "      <td>가장 간단한 경우에서 뜨겁고 밝은 별은 중심핵의 수소가 고갈될 때 팽창하기 시작하...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>청색거성</td>\n",
       "      <td>천문학에서 청색거성(靑色巨星, )은 광도 분류에서 III형(거성) 또는 II형(밝은...</td>\n",
       "      <td>0</td>\n",
       "      <td>BHB 별은 아직 커다란 수소껍질을 가지고 있다 해도 더 진화하여 헬륨 연소핵을 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>청색거성</td>\n",
       "      <td>천문학에서 청색거성(靑色巨星, )은 광도 분류에서 III형(거성) 또는 II형(밝은...</td>\n",
       "      <td>0</td>\n",
       "      <td>보통 청색거성으로 불리지 않는 더 진화한 뜨거운 별들도 있는데, 매우 밝고 극단적...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>청색거성</td>\n",
       "      <td>천문학에서 청색거성(靑色巨星, )은 광도 분류에서 III형(거성) 또는 II형(밝은...</td>\n",
       "      <td>0</td>\n",
       "      <td>순전히 이론적인 영역의 별은 적색왜성이 최종적으로 수조 년이 지난 미래에 중심핵의...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>엘자스-로트링겐 평의회 공화국</td>\n",
       "      <td>엘자스-로트링겐 평의회 공화국은 1차대전 말기 독일 혁명 와중에 엘자스-로트링겐에서...</td>\n",
       "      <td>0</td>\n",
       "      <td>엘자스-로트링겐 평의회 공화국은 1차대전 말기 독일 혁명 와중에 엘자스-로트링겐에서...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>엘자스-로트링겐 평의회 공화국</td>\n",
       "      <td>엘자스-로트링겐 평의회 공화국은 1차대전 말기 독일 혁명 와중에 엘자스-로트링겐에서...</td>\n",
       "      <td>0</td>\n",
       "      <td>엘자스-로트링겐 출신 병사들은 1918년 초부터 이미 불온한 낌새를 보이기 시작하...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>엘자스-로트링겐 평의회 공화국</td>\n",
       "      <td>엘자스-로트링겐 평의회 공화국은 1차대전 말기 독일 혁명 와중에 엘자스-로트링겐에서...</td>\n",
       "      <td>0</td>\n",
       "      <td>1918년 10월, 독일 황립해군의 수병들이 영국 왕립해군과 싸우기 위해 출항하라...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               title                                          full_text  \\\n",
       "0             카호올라웨섬  카호올라웨섬은 하와이 제도를 구성하는 8개의 화산섬 가운데 하나로 면적은 115.5...   \n",
       "1             카호올라웨섬  카호올라웨섬은 하와이 제도를 구성하는 8개의 화산섬 가운데 하나로 면적은 115.5...   \n",
       "2             카호올라웨섬  카호올라웨섬은 하와이 제도를 구성하는 8개의 화산섬 가운데 하나로 면적은 115.5...   \n",
       "3             카호올라웨섬  카호올라웨섬은 하와이 제도를 구성하는 8개의 화산섬 가운데 하나로 면적은 115.5...   \n",
       "4             카호올라웨섬  카호올라웨섬은 하와이 제도를 구성하는 8개의 화산섬 가운데 하나로 면적은 115.5...   \n",
       "5             카호올라웨섬  카호올라웨섬은 하와이 제도를 구성하는 8개의 화산섬 가운데 하나로 면적은 115.5...   \n",
       "6               청색거성  천문학에서 청색거성(靑色巨星, )은 광도 분류에서 III형(거성) 또는 II형(밝은...   \n",
       "7               청색거성  천문학에서 청색거성(靑色巨星, )은 광도 분류에서 III형(거성) 또는 II형(밝은...   \n",
       "8               청색거성  천문학에서 청색거성(靑色巨星, )은 광도 분류에서 III형(거성) 또는 II형(밝은...   \n",
       "9               청색거성  천문학에서 청색거성(靑色巨星, )은 광도 분류에서 III형(거성) 또는 II형(밝은...   \n",
       "10              청색거성  천문학에서 청색거성(靑色巨星, )은 광도 분류에서 III형(거성) 또는 II형(밝은...   \n",
       "11              청색거성  천문학에서 청색거성(靑色巨星, )은 광도 분류에서 III형(거성) 또는 II형(밝은...   \n",
       "12              청색거성  천문학에서 청색거성(靑色巨星, )은 광도 분류에서 III형(거성) 또는 II형(밝은...   \n",
       "13              청색거성  천문학에서 청색거성(靑色巨星, )은 광도 분류에서 III형(거성) 또는 II형(밝은...   \n",
       "14              청색거성  천문학에서 청색거성(靑色巨星, )은 광도 분류에서 III형(거성) 또는 II형(밝은...   \n",
       "15              청색거성  천문학에서 청색거성(靑色巨星, )은 광도 분류에서 III형(거성) 또는 II형(밝은...   \n",
       "16              청색거성  천문학에서 청색거성(靑色巨星, )은 광도 분류에서 III형(거성) 또는 II형(밝은...   \n",
       "17  엘자스-로트링겐 평의회 공화국  엘자스-로트링겐 평의회 공화국은 1차대전 말기 독일 혁명 와중에 엘자스-로트링겐에서...   \n",
       "18  엘자스-로트링겐 평의회 공화국  엘자스-로트링겐 평의회 공화국은 1차대전 말기 독일 혁명 와중에 엘자스-로트링겐에서...   \n",
       "19  엘자스-로트링겐 평의회 공화국  엘자스-로트링겐 평의회 공화국은 1차대전 말기 독일 혁명 와중에 엘자스-로트링겐에서...   \n",
       "\n",
       "    generated                                               text  \n",
       "0           0  카호올라웨섬은 하와이 제도를 구성하는 8개의 화산섬 가운데 하나로 면적은 115.5...  \n",
       "1           0   마우이섬에서 남서쪽으로 약 11km 정도 떨어진 곳에 위치하며 라나이섬의 남동쪽에...  \n",
       "2           0   1000년경부터 사람이 거주했으며 해안 지대에는 소규모 임시 어촌이 형성되었다. ...  \n",
       "3           0   1830년대에는 하와이 왕국의 카메하메하 3세 국왕에 의해 남자 죄수들의 유형지로...  \n",
       "4           0   1910년부터 1918년까지 하와이 준주가 섬의 원래 모습을 복원하기 위해 이 섬...  \n",
       "5           0   1941년 12월 7일에 일어난 일본 제국 해군의 진주만 공격을 계기로 카호올라웨...  \n",
       "6           0  천문학에서 청색거성(靑色巨星, )은 광도 분류에서 III형(거성) 또는 II형(밝은...  \n",
       "7           0   용어는 각자 다른 진화 단계에 있는 여러 가지 별에 적용되는데, 이들 모두 주계열...  \n",
       "8           0   청색거성이라는 명칭은 종종 매우 크고 뜨거운 주계열성과 같이, 다른 무겁고 밝은 ...  \n",
       "9           0   청색거성은 엄격히 정의된 단어가 아니어서 서로 다른 다양한 유형의 별에 폭넓게 사...  \n",
       "10          0   청색거성으로 표현되는 매우 차갑고 어두운 별은, 적색거성 단계를 지난 중간 질량의...  \n",
       "11          0   거성에 대해서 명확한 최대 한계는 없지만, O형 초반의 주계열성과 그와 거의 동일...  \n",
       "12          0   HR 도표의 청색거성 영역에서 발견되는 별은 일생에서의 단계가 각자 크게 다를 수...  \n",
       "13          0   가장 간단한 경우에서 뜨겁고 밝은 별은 중심핵의 수소가 고갈될 때 팽창하기 시작하...  \n",
       "14          0   BHB 별은 아직 커다란 수소껍질을 가지고 있다 해도 더 진화하여 헬륨 연소핵을 ...  \n",
       "15          0   보통 청색거성으로 불리지 않는 더 진화한 뜨거운 별들도 있는데, 매우 밝고 극단적...  \n",
       "16          0   순전히 이론적인 영역의 별은 적색왜성이 최종적으로 수조 년이 지난 미래에 중심핵의...  \n",
       "17          0  엘자스-로트링겐 평의회 공화국은 1차대전 말기 독일 혁명 와중에 엘자스-로트링겐에서...  \n",
       "18          0   엘자스-로트링겐 출신 병사들은 1918년 초부터 이미 불온한 낌새를 보이기 시작하...  \n",
       "19          0   1918년 10월, 독일 황립해군의 수병들이 영국 왕립해군과 싸우기 위해 출항하라...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_paragraph_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8ba12f93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 StratifiedGroupKFold LightGBM 학습 시작 (데이터 누수 방지)\n",
      "그룹 교차검증을 위한 그룹 생성 완료: 92861개 고유 글\n",
      "\n",
      "🔄 5-Fold Group 교차검증 시작...\n",
      "\n",
      "📁 Fold 1/5\n",
      "  훈련 세트 AI 비율: 0.100\n",
      "  검증 세트 AI 비율: 0.099\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[78]\tvalid's auc: 0.712611\n",
      "  Fold 1 AUC: 0.71261\n",
      "\n",
      "📁 Fold 2/5\n",
      "  훈련 세트 AI 비율: 0.100\n",
      "  검증 세트 AI 비율: 0.100\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[159]\tvalid's auc: 0.709926\n",
      "  Fold 2 AUC: 0.70993\n",
      "\n",
      "📁 Fold 3/5\n",
      "  훈련 세트 AI 비율: 0.100\n",
      "  검증 세트 AI 비율: 0.100\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[332]\tvalid's auc: 0.72295\n",
      "  Fold 3 AUC: 0.72295\n",
      "\n",
      "📁 Fold 4/5\n",
      "  훈련 세트 AI 비율: 0.101\n",
      "  검증 세트 AI 비율: 0.096\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[70]\tvalid's auc: 0.712711\n",
      "  Fold 4 AUC: 0.71271\n",
      "\n",
      "📁 Fold 5/5\n",
      "  훈련 세트 AI 비율: 0.099\n",
      "  검증 세트 AI 비율: 0.104\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[153]\tvalid's auc: 0.707323\n",
      "  Fold 5 AUC: 0.70732\n",
      "\n",
      "🏆 교차검증 결과 (데이터 누수 방지됨):\n",
      "  평균 AUC: 0.71310 (±0.00531)\n",
      "  OOF AUC: 0.71047\n",
      "  최고 Fold AUC: 0.72295\n",
      "  최저 Fold AUC: 0.70732\n"
     ]
    }
   ],
   "source": [
    "print(\"🎯 StratifiedGroupKFold LightGBM 학습 시작 (데이터 누수 방지)\")\n",
    "\n",
    "# Optuna 최적화된 파라미터\n",
    "best_params = {\n",
    "    'learning_rate': 0.043,\n",
    "    'num_leaves': 41,\n",
    "    'max_depth': 6,\n",
    "    'subsample': 0.7,\n",
    "    'colsample_bytree': 0.84,\n",
    "    'lambda_l1': 9.28e-06,\n",
    "    'lambda_l2': 0.0021,\n",
    "    'objective': 'binary',\n",
    "    'metric': 'auc',\n",
    "    'verbosity': -1,\n",
    "    'boosting_type': 'gbdt',\n",
    "    'random_state': 42,\n",
    "    'n_estimators': 1000,\n",
    "    'device': 'cpu',  # GPU → CPU 변경\n",
    "    'n_jobs': 16\n",
    "}\n",
    "\n",
    "# --- 그룹 교차검증 설정 ---\n",
    "# 1. 그룹 정보 생성 (원본 글 ID 기준)\n",
    "# clean_indices는 정제된 문단들의 인덱스입니다.\n",
    "# 이 인덱스를 사용하여 원본 train_paragraph_df에서 글 ID('id')를 가져와 그룹으로 사용합니다.\n",
    "groups = train_paragraph_df['title'].iloc[clean_indices].values\n",
    "print(f\"그룹 교차검증을 위한 그룹 생성 완료: {len(np.unique(groups))}개 고유 글\")\n",
    "\n",
    "# 2. StratifiedGroupKFold 설정\n",
    "sgkf = StratifiedGroupKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# OOF 예측을 위한 배열 초기화\n",
    "oof_predictions = np.zeros(len(X_train_clean))\n",
    "fold_models = []\n",
    "fold_scores = []\n",
    "\n",
    "print(f\"\\n🔄 5-Fold Group 교차검증 시작...\")\n",
    "\n",
    "# 3. 교차검증 루프 변경\n",
    "# split 메서드에 groups 정보를 추가합니다.\n",
    "for fold, (train_idx, val_idx) in enumerate(sgkf.split(X_train_clean, y_train_clean, groups)):\n",
    "    print(f\"\\n📁 Fold {fold + 1}/5\")\n",
    "    \n",
    "    X_fold_train, X_fold_val = X_train_clean[train_idx], X_train_clean[val_idx]\n",
    "    y_fold_train, y_fold_val = y_train_clean[train_idx], y_train_clean[val_idx]\n",
    "    \n",
    "    # 클래스 분포 확인\n",
    "    train_ratio = y_fold_train.mean()\n",
    "    val_ratio = y_fold_val.mean()\n",
    "    print(f\"  훈련 세트 AI 비율: {train_ratio:.3f}\")\n",
    "    print(f\"  검증 세트 AI 비율: {val_ratio:.3f}\")\n",
    "    \n",
    "    # LightGBM 데이터셋 생성\n",
    "    train_dataset = lgb.Dataset(X_fold_train, label=y_fold_train)\n",
    "    val_dataset = lgb.Dataset(X_fold_val, label=y_fold_val, reference=train_dataset)\n",
    "    \n",
    "    # 모델 학습\n",
    "    fold_model = lgb.train(\n",
    "        best_params,\n",
    "        train_dataset,\n",
    "        valid_sets=[val_dataset],\n",
    "        valid_names=['valid'],\n",
    "        callbacks=[\n",
    "            lgb.early_stopping(stopping_rounds=100),\n",
    "            lgb.log_evaluation(period=0)  # 로그 출력 최소화\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # 검증 세트 예측\n",
    "    val_pred = fold_model.predict(X_fold_val, num_iteration=fold_model.best_iteration)\n",
    "    oof_predictions[val_idx] = val_pred\n",
    "    \n",
    "    # AUC 점수 계산\n",
    "    fold_auc = roc_auc_score(y_fold_val, val_pred)\n",
    "    fold_scores.append(fold_auc)\n",
    "    fold_models.append(fold_model)\n",
    "    \n",
    "    print(f\"  Fold {fold + 1} AUC: {fold_auc:.5f}\")\n",
    "\n",
    "# 전체 OOF AUC 계산\n",
    "oof_auc = roc_auc_score(y_train_clean, oof_predictions)\n",
    "mean_auc = np.mean(fold_scores)\n",
    "std_auc = np.std(fold_scores)\n",
    "\n",
    "print(f\"\\n🏆 교차검증 결과 (데이터 누수 방지됨):\")\n",
    "print(f\"  평균 AUC: {mean_auc:.5f} (±{std_auc:.5f})\")\n",
    "print(f\"  OOF AUC: {oof_auc:.5f}\")\n",
    "print(f\"  최고 Fold AUC: {max(fold_scores):.5f}\")\n",
    "print(f\"  최저 Fold AUC: {min(fold_scores):.5f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ed2ff770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔮 테스트 데이터 최종 예측 및 제출 파일 생성\n",
      "  📊 앙상블 예측 수행 중...\n",
      "✅ 테스트 특징 로드 완료: (1962, 1664)\n",
      "  Fold 1 예측 완료\n",
      "  Fold 2 예측 완료\n",
      "  Fold 3 예측 완료\n",
      "  Fold 4 예측 완료\n",
      "  Fold 5 예측 완료\n",
      "\n",
      "🎉 제출 파일 생성 완료:\n",
      "  타임스탬프 파일: results/submission_hybrid_lgb_20250714_0522.csv\n",
      "  기본 파일: submission.csv\n",
      "  샘플 수: 1,962개\n",
      "\n",
      "📋 최종 파이프라인 완료:\n",
      "  🎯 StratifiedKFold 학습: 5-Fold CV 완료\n",
      "  🏆 최종 OOF AUC: 0.71047\n",
      "  🔮 앙상블 예측: 5개 모델 평균\n",
      "  ⏰ 완료 시간: 2025-07-14 05:22:53.046723\n",
      "✅ 모든 작업 완료! 제출 파일을 대회에 업로드하세요.\n"
     ]
    }
   ],
   "source": [
    "print(\"🔮 테스트 데이터 최종 예측 및 제출 파일 생성\")\n",
    "\n",
    "# 5개 폴드 모델의 평균 예측\n",
    "print(\"  📊 앙상블 예측 수행 중...\")\n",
    "X_test_features = np.load('data/X_test_paragraph_features.npy')\n",
    "print(f\"✅ 테스트 특징 로드 완료: {X_test_features.shape}\")\n",
    "test_predictions_list = []\n",
    "\n",
    "if 'fold_models' not in locals():\n",
    "    print(\"❌ fold_models가 정의되지 않았습니다.\")\n",
    "    print(\"StratifiedKFold 학습 셀을 먼저 실행해주세요.\")\n",
    "\n",
    "for i, model in enumerate(fold_models):\n",
    "    fold_pred = model.predict(X_test_features, num_iteration=model.best_iteration)\n",
    "    test_predictions_list.append(fold_pred)\n",
    "    print(f\"  Fold {i+1} 예측 완료\")\n",
    "\n",
    "# 평균 앙상블\n",
    "ensemble_predictions = np.mean(test_predictions_list, axis=0)\n",
    "\n",
    "# 제출 파일 생성\n",
    "sample_submission = pd.read_csv('data/sample_submission.csv')\n",
    "sample_submission['generated'] = ensemble_predictions\n",
    "\n",
    "# 결과 폴더 생성 및 파일 저장\n",
    "os.makedirs('results', exist_ok=True)\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M\")\n",
    "submission_filename = f'results/submission_hybrid_lgb_{timestamp}.csv'\n",
    "\n",
    "sample_submission.to_csv(submission_filename, index=False)\n",
    "\n",
    "# 기본 제출 파일도 생성\n",
    "sample_submission.to_csv('submission.csv', index=False)\n",
    "\n",
    "print(f\"\\n🎉 제출 파일 생성 완료:\")\n",
    "print(f\"  타임스탬프 파일: {submission_filename}\")\n",
    "print(f\"  기본 파일: submission.csv\")\n",
    "print(f\"  샘플 수: {len(sample_submission):,}개\")\n",
    "\n",
    "# 최종 결과 요약\n",
    "print(f\"\\n📋 최종 파이프라인 완료:\")\n",
    "print(f\"  🎯 StratifiedKFold 학습: 5-Fold CV 완료\")\n",
    "print(f\"  🏆 최종 OOF AUC: {oof_auc:.5f}\")\n",
    "print(f\"  🔮 앙상블 예측: 5개 모델 평균\")\n",
    "print(f\"  ⏰ 완료 시간: {datetime.now()}\")\n",
    "print(\"✅ 모든 작업 완료! 제출 파일을 대회에 업로드하세요.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
