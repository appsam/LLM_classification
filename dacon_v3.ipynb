{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43dd2334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "# === í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ===\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import gc\n",
    "import time\n",
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "# ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ ë° ë„êµ¬\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# ë”¥ëŸ¬ë‹ ë° ì„ë² ë”©\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "print(\"âœ… ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0557a89c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë°ì´í„°ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤...\n",
      "ë¬¸ë‹¨ ë¶„ë¦¬ëœ ë°ì´í„°í”„ë ˆì„ì„ ìƒì„±í•©ë‹ˆë‹¤...\n",
      "ë¯¸ë¦¬ ìƒì„±ëœ íŠ¹ì§•(.npy) íŒŒì¼ì„ ë¡œë“œí•©ë‹ˆë‹¤...\n",
      "í›ˆë ¨ ë°ì´í„°: (1226364, 4)\n",
      "ê¸°ì¡´ í›ˆë ¨ íŠ¹ì§•: (1226364, 1664)\n",
      "âœ… ë°ì´í„° ë¡œë“œ ë° ì¤€ë¹„ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "# === ê¸°ë³¸ ë°ì´í„° ë¡œë“œ ===\n",
    "print(\"ë°ì´í„°ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤...\")\n",
    "train_df_original = pd.read_csv('data/train.csv', encoding='utf-8-sig')\n",
    "test_df = pd.read_csv('data/test.csv', encoding='utf-8-sig')\n",
    "sample_submission = pd.read_csv('data/sample_submission.csv', encoding='utf-8-sig')\n",
    "\n",
    "# === ë¬¸ë‹¨ ë¶„ë¦¬ ===\n",
    "print(\"ë¬¸ë‹¨ ë¶„ë¦¬ëœ ë°ì´í„°í”„ë ˆì„ì„ ìƒì„±í•©ë‹ˆë‹¤...\")\n",
    "train_df_original['paragraphs'] = train_df_original['full_text'].str.split('\\n')\n",
    "train_paragraph_df = train_df_original.explode('paragraphs').rename(columns={'paragraphs': 'text'})\n",
    "train_paragraph_df.dropna(subset=['text'], inplace=True)\n",
    "train_paragraph_df = train_paragraph_df[train_paragraph_df['text'].str.strip().astype(bool)].reset_index(drop=True)\n",
    "\n",
    "# === ë¯¸ë¦¬ ìƒì„±ëœ ê¸°ë³¸ íŠ¹ì§• ë¡œë“œ ===\n",
    "print(\"ë¯¸ë¦¬ ìƒì„±ëœ íŠ¹ì§•(.npy) íŒŒì¼ì„ ë¡œë“œí•©ë‹ˆë‹¤...\")\n",
    "X_train_paragraph_features = np.load('data/X_train_paragraph_features.npy')\n",
    "X_test_paragraph_features = np.load('data/X_test_paragraph_features.npy')\n",
    "\n",
    "X_train_final = np.load('X_train_final.npy')\n",
    "X_test_final = np.load('X_test_final.npy')\n",
    "\n",
    "print(f\"í›ˆë ¨ ë°ì´í„°: {train_paragraph_df.shape}\")\n",
    "print(f\"ê¸°ì¡´ í›ˆë ¨ íŠ¹ì§•: {X_train_paragraph_features.shape}\")\n",
    "print(\"âœ… ë°ì´í„° ë¡œë“œ ë° ì¤€ë¹„ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5aacf90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"--- 1ë‹¨ê³„ (ì—…ê·¸ë ˆì´ë“œ): ë¬¸ì²´/í†µê³„ì  íŠ¹ì§• ìƒì„± ì‹œì‘ ---\")\n",
    "\n",
    "# # í•œêµ­ì–´ ë¶ˆìš©ì–´ ë¦¬ìŠ¤íŠ¸ (í•„ìš”ì— ë”°ë¼ ì¶”ê°€/ì‚­ì œ ê°€ëŠ¥)\n",
    "# STOPWORDS = set(['ì€', 'ëŠ”', 'ì´', 'ê°€', 'ì„', 'ë¥¼', 'ì˜', 'ì—', 'ì™€', 'ê³¼', 'ë„', 'ìœ¼ë¡œ', 'ë¡œ',\n",
    "#                  'í•˜ë‹¤', 'ì´ë‹¤', 'ìˆë‹¤', 'ê·¸', 'ì €', 'ì´ê²ƒ', 'ì €ê²ƒ', 'ê·¸ê²ƒ', 'ë°', 'ë“±'])\n",
    "# if 'paragraph_text' in test_df.columns:\n",
    "#     print(\"test_dfì˜ 'paragraph_text' ì»¬ëŸ¼ì„ 'text'ë¡œ ë³€ê²½í•©ë‹ˆë‹¤.\")\n",
    "#     test_df.rename(columns={'paragraph_text': 'text'}, inplace=True)\n",
    "\n",
    "# def create_statistical_features(df):\n",
    "#     \"\"\"ë” ì˜ë¯¸ìˆëŠ” í†µê³„/ë¬¸ì²´ì  íŠ¹ì§•ì„ ìƒì„±í•©ë‹ˆë‹¤.\"\"\"\n",
    "#     # ê¸°ë³¸ ê°œìˆ˜ íŠ¹ì§•\n",
    "#     df['text_len'] = df['text'].str.len()\n",
    "#     df['word_count'] = df['text'].str.split().str.len()\n",
    "#     df['sentence_count'] = df['text'].str.count(r'[.!?]') + 1\n",
    "#     df['comma_count'] = df['text'].str.count(',')\n",
    "#     # SyntaxWarning í•´ê²° (r ì¶”ê°€)\n",
    "#     df['special_char_count'] = df['text'].str.count(r'[^A-Za-z0-9ê°€-í£\\s]')\n",
    "#     df['lexical_diversity'] = df['text'].apply(lambda x: len(set(x.split())) / (len(x.split()) + 1e-6))\n",
    "    \n",
    "#     # [ìƒˆë¡œìš´ íŠ¹ì§•] ë¹„ìœ¨ íŠ¹ì§• (0ìœ¼ë¡œ ë‚˜ëˆ„ëŠ” ê²ƒì„ ë°©ì§€í•˜ê¸° ìœ„í•´ 1e-6 ì¶”ê°€)\n",
    "#     df['avg_sentence_len'] = df['word_count'] / df['sentence_count']\n",
    "#     df['avg_word_len'] = df['text_len'] / (df['word_count'] + 1e-6)\n",
    "    \n",
    "#     # [ìƒˆë¡œìš´ íŠ¹ì§•] ë¶ˆìš©ì–´ ë¹„ìœ¨\n",
    "#     df['stopword_count'] = df['text'].apply(lambda x: sum(word in STOPWORDS for word in x.split()))\n",
    "#     df['stopword_ratio'] = df['stopword_count'] / (df['word_count'] + 1e-6)\n",
    "    \n",
    "#     # ê²°ì¸¡ì¹˜(NaN)ê°€ ë°œìƒí•  ê²½ìš° 0ìœ¼ë¡œ ì±„ì›€\n",
    "#     df.fillna(0, inplace=True)\n",
    "    \n",
    "#     return df\n",
    "\n",
    "# # í›ˆë ¨ ë° í…ŒìŠ¤íŠ¸ ë°ì´í„°ì— ìƒˆë¡œìš´ í•¨ìˆ˜ ì ìš©\n",
    "# train_paragraph_df = create_statistical_features(train_paragraph_df)\n",
    "# test_df = create_statistical_features(test_df)\n",
    "\n",
    "# # ì‚¬ìš©í•  íŠ¹ì§• ì´ë¦„ ë¦¬ìŠ¤íŠ¸ ì—…ë°ì´íŠ¸\n",
    "# new_stat_feature_names = [\n",
    "#     'text_len', 'word_count', 'sentence_count', 'comma_count', 'special_char_count', 'lexical_diversity',\n",
    "#     'avg_sentence_len', 'avg_word_len', 'stopword_ratio' # stopword_countëŠ” ë¹„ìœ¨ ê³„ì‚°ì—ë§Œ ì‚¬ìš©\n",
    "# ]\n",
    "# train_stat_features = train_paragraph_df[new_stat_feature_names].values\n",
    "# test_stat_features = test_df[new_stat_feature_names].values\n",
    "\n",
    "# # ê¸°ì¡´ íŠ¹ì§•ê³¼ ìƒˆë¡œ ë§Œë“  í†µê³„ íŠ¹ì§•ì„ ê²°í•©\n",
    "# X_train_combined = np.c_[X_train_paragraph_features, train_stat_features]\n",
    "# X_test_combined = np.c_[X_test_paragraph_features, test_stat_features]\n",
    "\n",
    "# print(\"âœ… ì—…ê·¸ë ˆì´ë“œëœ í†µê³„ íŠ¹ì§• ìƒì„± ë° ê²°í•© ì™„ë£Œ!\")\n",
    "# print(f\"1ë‹¨ê³„ í›„ í›ˆë ¨ íŠ¹ì§• shape: {X_train_combined.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e3aa099",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"--- 2ë‹¨ê³„: KoELECTRA ì„ë² ë”© ìƒì„± ì‹œì‘ ---\")\n",
    "\n",
    "# # GPU ì„¤ì •\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# print(f\"Using device: {device}\")\n",
    "\n",
    "# model_name = \"monologg/koelectra-base-v3-discriminator\"\n",
    "# koelectra_tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# # SafeTensors ì‚¬ìš© ë° RTX 3060 ìµœì í™”\n",
    "# try:\n",
    "#     koelectra_model = AutoModel.from_pretrained(\n",
    "#         model_name,\n",
    "#         use_safetensors=True,  # ë³´ì•ˆ ê°•í™”\n",
    "#         torch_dtype=torch.float16,  # ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± í–¥ìƒ\n",
    "#         device_map=\"auto\"  # ìë™ ë©”ëª¨ë¦¬ ê´€ë¦¬\n",
    "#     ).to(device)\n",
    "#     print(\"âœ… SafeTensors í˜•ì‹ìœ¼ë¡œ ëª¨ë¸ ë¡œë“œ ì„±ê³µ\")\n",
    "# except Exception as e:\n",
    "#     print(f\"âš ï¸ SafeTensors ë¡œë“œ ì‹¤íŒ¨, ê¸°ë³¸ ë°©ì‹ìœ¼ë¡œ ì‹œë„: {e}\")\n",
    "#     koelectra_model = AutoModel.from_pretrained(model_name).half().to(device)\n",
    "\n",
    "# def get_embeddings(texts, model, tokenizer, batch_size=128):  # RTX 3060 ìµœì í™”: 256â†’128\n",
    "#     \"\"\"ì£¼ì–´ì§„ ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì €ë¡œ í…ìŠ¤íŠ¸ ì„ë² ë”©ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.\"\"\"\n",
    "#     all_embeddings = []\n",
    "#     model.eval()\n",
    "    \n",
    "#     for i in tqdm(range(0, len(texts), batch_size), desc=\"Extracting Embeddings\"):\n",
    "#         batch = texts[i:i+batch_size]\n",
    "#         batch_dict = tokenizer(\n",
    "#             [str(t) for t in batch], \n",
    "#             max_length=256, \n",
    "#             padding=True, \n",
    "#             truncation=True, \n",
    "#             return_tensors='pt'\n",
    "#         ).to(device)\n",
    "        \n",
    "#         with torch.no_grad(), torch.cuda.amp.autocast():\n",
    "#             outputs = model(**batch_dict)\n",
    "        \n",
    "#         embeddings = outputs.last_hidden_state[:, 0, :].float().cpu().numpy()\n",
    "#         all_embeddings.append(embeddings)\n",
    "        \n",
    "#         # ë©”ëª¨ë¦¬ ì •ë¦¬ (10 ë°°ì¹˜ë§ˆë‹¤)\n",
    "#         if i % 10 == 0:\n",
    "#             torch.cuda.empty_cache()\n",
    "    \n",
    "#     return np.vstack(all_embeddings)\n",
    "\n",
    "# # GPU ë©”ëª¨ë¦¬ ìƒíƒœ í™•ì¸\n",
    "# def check_gpu_memory():\n",
    "#     if torch.cuda.is_available():\n",
    "#         print(f\"GPU Memory - Allocated: {torch.cuda.memory_allocated(0)/1024**3:.2f}GB, \"\n",
    "#               f\"Reserved: {torch.cuda.memory_reserved(0)/1024**3:.2f}GB\")\n",
    "\n",
    "# print(\"ëª¨ë¸ ë¡œë”© í›„ GPU ë©”ëª¨ë¦¬ ìƒíƒœ:\")\n",
    "# check_gpu_memory()\n",
    "\n",
    "# # KoELECTRA ì„ë² ë”© ìƒì„±\n",
    "# print(\"í›ˆë ¨ ë°ì´í„° ì„ë² ë”© ìƒì„± ì¤‘...\")\n",
    "# ko_electra_train_features = get_embeddings(train_paragraph_df['text'].tolist(), koelectra_model, koelectra_tokenizer)\n",
    "\n",
    "# print(\"í…ŒìŠ¤íŠ¸ ë°ì´í„° ì„ë² ë”© ìƒì„± ì¤‘...\")\n",
    "# ko_electra_test_features = get_embeddings(test_df['text'].tolist(), koelectra_model, koelectra_tokenizer)\n",
    "\n",
    "# # GPU ë©”ëª¨ë¦¬ ì •ë¦¬\n",
    "# del koelectra_model\n",
    "# gc.collect()\n",
    "# torch.cuda.empty_cache()\n",
    "\n",
    "# print(\"ë©”ëª¨ë¦¬ ì •ë¦¬ í›„ GPU ìƒíƒœ:\")\n",
    "# check_gpu_memory()\n",
    "\n",
    "# # 1ë‹¨ê³„ì—ì„œ ë§Œë“  íŠ¹ì§•ì— KoELECTRA ì„ë² ë”©ì„ ìµœì¢…ì ìœ¼ë¡œ ê²°í•©\n",
    "# X_train_final = np.c_[X_train_combined, ko_electra_train_features]\n",
    "# X_test_final = np.c_[X_test_combined, ko_electra_test_features]\n",
    "\n",
    "# # ë‚˜ì¤‘ì„ ìœ„í•´ ìµœì¢… íŠ¹ì§• íŒŒì¼ì„ ì €ì¥í•´ë‘ëŠ” ê²ƒì´ ì•ˆì „í•©ë‹ˆë‹¤.\n",
    "# print(\"ìµœì¢… íŠ¹ì§• íŒŒì¼ì„ ì €ì¥í•©ë‹ˆë‹¤...\")\n",
    "# np.save('X_train_final.npy', X_train_final)\n",
    "# np.save('X_test_final.npy', X_test_final)\n",
    "\n",
    "# print(\"âœ… KoELECTRA ì„ë² ë”© ê²°í•© ë° ìµœì¢… íŠ¹ì§• ìƒì„± ì™„ë£Œ!\")\n",
    "# print(f\"ìµœì¢… í›ˆë ¨ íŠ¹ì§• shape: {X_train_final.shape}\")\n",
    "# print(f\"ìµœì¢… í…ŒìŠ¤íŠ¸ íŠ¹ì§• shape: {X_test_final.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f2b6a15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 3ë‹¨ê³„: ì˜ì‚¬ ë¼ë²¨ë§ìœ¼ë¡œ í•™ìŠµ ë°ì´í„° ì •ì œ ì‹œì‘ ---\n",
      "1ì°¨ ëª¨ë¸ì„ Noisy Labelë¡œ í•™ìŠµí•©ë‹ˆë‹¤...\n",
      "[LightGBM] [Info] Number of positive: 100712, number of negative: 1125652\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 18.613746 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 613406\n",
      "[LightGBM] [Info] Number of data points in the train set: 1226364, number of used features: 2441\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.082122 -> initscore=-2.413853\n",
      "[LightGBM] [Info] Start training from score -2.413853\n",
      "ëª¨ë“  í›ˆë ¨ ë¬¸ë‹¨ì— ëŒ€í•´ AIì¼ í™•ë¥ ì„ ì˜ˆì¸¡í•©ë‹ˆë‹¤...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\develop\\deep_learning\\DACON\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì‹ ë¢°ë„ ë†’ì€ ë°ì´í„°ë§Œ ì„ ë³„í•˜ì—¬ ìµœì¢… í›ˆë ¨ ì„¸íŠ¸ë¥¼ êµ¬ì„±í•©ë‹ˆë‹¤...\n",
      "âœ… ë°ì´í„° ì •ì œ ì™„ë£Œ!\n",
      "ì›ë³¸ í›ˆë ¨ ë°ì´í„° ìˆ˜: 1,226,364\n",
      "ì •ì œëœ í›ˆë ¨ ë°ì´í„° ìˆ˜: 1,153,741\n",
      "ì •ì œëœ AI ë¬¸ë‹¨ ìˆ˜: 28,089\n"
     ]
    }
   ],
   "source": [
    "print(\"--- 3ë‹¨ê³„: ì˜ì‚¬ ë¼ë²¨ë§ìœ¼ë¡œ í•™ìŠµ ë°ì´í„° ì •ì œ ì‹œì‘ ---\")\n",
    "\n",
    "# 1. 1ì°¨ ëª¨ë¸(LGBM)ì„ Noisy Labelë¡œ ë¹ ë¥´ê²Œ í•™ìŠµ\n",
    "print(\"1ì°¨ ëª¨ë¸ì„ Noisy Labelë¡œ í•™ìŠµí•©ë‹ˆë‹¤...\")\n",
    "lgb_pseudo = lgb.LGBMClassifier(objective='binary', metric='auc', random_state=42, n_jobs=-1)\n",
    "noisy_labels = train_paragraph_df['generated'].values\n",
    "lgb_pseudo.fit(X_train_final, noisy_labels)\n",
    "\n",
    "# 2. ëª¨ë“  í›ˆë ¨ ë°ì´í„°ì— ëŒ€í•´ AIì¼ í™•ë¥  ì˜ˆì¸¡\n",
    "print(\"ëª¨ë“  í›ˆë ¨ ë¬¸ë‹¨ì— ëŒ€í•´ AIì¼ í™•ë¥ ì„ ì˜ˆì¸¡í•©ë‹ˆë‹¤...\")\n",
    "train_preds_proba = lgb_pseudo.predict_proba(X_train_final)[:, 1]\n",
    "\n",
    "# 3. ì‹ ë¢°ë„ ë†’ì€ ë°ì´í„°ë§Œ ì„ ë³„í•˜ì—¬ ìµœì¢… í›ˆë ¨ ì„¸íŠ¸ êµ¬ì„±\n",
    "print(\"ì‹ ë¢°ë„ ë†’ì€ ë°ì´í„°ë§Œ ì„ ë³„í•˜ì—¬ ìµœì¢… í›ˆë ¨ ì„¸íŠ¸ë¥¼ êµ¬ì„±í•©ë‹ˆë‹¤...\")\n",
    "ai_doc_indices = train_paragraph_df.index[train_paragraph_df['generated'] == 1]\n",
    "human_doc_indices = train_paragraph_df.index[train_paragraph_df['generated'] == 0]\n",
    "\n",
    "# AI ê¸€ ì¤‘ì—ì„œ, 1ì°¨ ëª¨ë¸ì´ AIì¼ í™•ë¥ ì´ 0.9 ì´ìƒì´ë¼ê³  ë§¤ìš° ê°•í•˜ê²Œ ì˜ˆì¸¡í•œ ë¬¸ë‹¨ë§Œ ì„ íƒ\n",
    "CONFIDENCE_THRESHOLD = 0.9\n",
    "confident_ai_indices = ai_doc_indices[train_preds_proba[ai_doc_indices] > CONFIDENCE_THRESHOLD]\n",
    "\n",
    "# ìµœì¢… í›ˆë ¨ì— ì‚¬ìš©í•  ì¸ë±ìŠ¤: (í™•ì‹¤í•œ ì‚¬ëŒ ê¸€) + (ë§¤ìš° í™•ì‹¤í•œ AI ê¸€)\n",
    "final_clean_indices = np.concatenate([human_doc_indices, confident_ai_indices])\n",
    "np.random.shuffle(final_clean_indices)\n",
    "\n",
    "# ìµœì¢…ì ìœ¼ë¡œ ì •ì œëœ í›ˆë ¨ ë°ì´í„° ìƒì„±\n",
    "X_train_clean = X_train_final[final_clean_indices]\n",
    "y_train_clean = train_paragraph_df['generated'].iloc[final_clean_indices].values\n",
    "groups_clean = train_paragraph_df['title'].iloc[final_clean_indices].values\n",
    "\n",
    "print(f\"âœ… ë°ì´í„° ì •ì œ ì™„ë£Œ!\")\n",
    "print(f\"ì›ë³¸ í›ˆë ¨ ë°ì´í„° ìˆ˜: {len(X_train_final):,}\")\n",
    "print(f\"ì •ì œëœ í›ˆë ¨ ë°ì´í„° ìˆ˜: {len(X_train_clean):,}\")\n",
    "print(f\"ì •ì œëœ AI ë¬¸ë‹¨ ìˆ˜: {(y_train_clean == 1).sum():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24672de8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 4-1ë‹¨ê³„: LightGBM ëª¨ë¸ í•™ìŠµ ì‹œì‘ (íŠ¹ì§• ì„ íƒ í¬í•¨) ---\n",
      "ë°ì´í„° íƒ€ì…ì„ float32ë¡œ ë³€ê²½í•˜ì—¬ ë©”ëª¨ë¦¬ ë¶€ë‹´ì„ ì¤„ì…ë‹ˆë‹¤...\n",
      "\n",
      "íŠ¹ì§• ì„ íƒì„ ì‹œì‘í•©ë‹ˆë‹¤...\n",
      "200,000ê°œì˜ ìƒ˜í”Œë¡œ íŠ¹ì§• ì¤‘ìš”ë„ ì¸¡ì • ëª¨ë¸ì„ í•™ìŠµí•©ë‹ˆë‹¤...\n",
      "[LightGBM] [Info] Number of positive: 4899, number of negative: 195101\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 3.764241 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 613432\n",
      "[LightGBM] [Info] Number of data points in the train set: 200000, number of used features: 2441\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.024495 -> initscore=-3.684486\n",
      "[LightGBM] [Info] Start training from score -3.684486\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "ì¤‘ìš”ë„ ìƒìœ„ 800ê°œì˜ íŠ¹ì§•ë§Œ ì„ íƒí•˜ì—¬ ìƒˆë¡œìš´ ë°ì´í„°ì…‹ì„ ìƒì„±í•©ë‹ˆë‹¤.\n",
      "íŠ¹ì§• ì„ íƒ ì™„ë£Œ! ìƒˆë¡œìš´ í›ˆë ¨ ë°ì´í„° shape: (1153741, 800)\n",
      "\n",
      "ì„ íƒëœ íŠ¹ì§•ìœ¼ë¡œ ìµœì¢… ëª¨ë¸ í•™ìŠµì„ ì‹œì‘í•©ë‹ˆë‹¤...\n",
      "--- Fold 1 (LGBM) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\develop\\deep_learning\\DACON\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\develop\\deep_learning\\DACON\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 (LGBM) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\develop\\deep_learning\\DACON\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\develop\\deep_learning\\DACON\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 (LGBM) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\develop\\deep_learning\\DACON\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\develop\\deep_learning\\DACON\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 (LGBM) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\develop\\deep_learning\\DACON\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\develop\\deep_learning\\DACON\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 5 (LGBM) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\develop\\deep_learning\\DACON\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\develop\\deep_learning\\DACON\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ† LightGBM ìµœì¢… OOF AUC: 0.99886\n"
     ]
    }
   ],
   "source": [
    "print(\"--- 4-1ë‹¨ê³„: LightGBM ëª¨ë¸ í•™ìŠµ ì‹œì‘ (íŠ¹ì§• ì„ íƒ í¬í•¨) ---\")\n",
    "\n",
    "# --- ë©”ëª¨ë¦¬ ì ˆì•½ì„ ìœ„í•œ ë°ì´í„° íƒ€ì… ë³€ê²½ ---\n",
    "print(\"ë°ì´í„° íƒ€ì…ì„ float32ë¡œ ë³€ê²½í•˜ì—¬ ë©”ëª¨ë¦¬ ë¶€ë‹´ì„ ì¤„ì…ë‹ˆë‹¤...\")\n",
    "X_train_clean = X_train_clean.astype('float32')\n",
    "X_test_final = X_test_final.astype('float32')\n",
    "gc.collect()\n",
    "\n",
    "# --- íŠ¹ì§• ì„ íƒ(Feature Selection) ì‹œì‘ ---\n",
    "print(\"\\níŠ¹ì§• ì„ íƒì„ ì‹œì‘í•©ë‹ˆë‹¤...\")\n",
    "\n",
    "# 1. ì¤‘ìš”ë„ ì¸¡ì •ì„ ìœ„í•´ ë°ì´í„°ì˜ ì¼ë¶€ ìƒ˜í”Œ(20ë§Œê°œ)ë§Œ ì‚¬ìš©\n",
    "SAMPLE_SIZE = 200000\n",
    "if len(X_train_clean) > SAMPLE_SIZE:\n",
    "    sample_indices = np.random.choice(len(X_train_clean), SAMPLE_SIZE, replace=False)\n",
    "    X_train_sample = X_train_clean[sample_indices]\n",
    "    y_train_sample = y_train_clean[sample_indices]\n",
    "else:\n",
    "    X_train_sample, y_train_sample = X_train_clean, y_train_clean\n",
    "\n",
    "# 2. ìƒ˜í”Œ ë°ì´í„°ë¡œ ë‹¨ì¼ LGBM ëª¨ë¸ì„ ë¹ ë¥´ê²Œ í•™ìŠµ\n",
    "print(f\"{len(X_train_sample):,}ê°œì˜ ìƒ˜í”Œë¡œ íŠ¹ì§• ì¤‘ìš”ë„ ì¸¡ì • ëª¨ë¸ì„ í•™ìŠµí•©ë‹ˆë‹¤...\")\n",
    "fs_model = lgb.LGBMClassifier(objective='binary', metric='auc', n_estimators=500, n_jobs=16, random_state=42)\n",
    "fs_model.fit(X_train_sample, y_train_sample)\n",
    "\n",
    "# 3. ì¤‘ìš”ë„ê°€ ë†’ì€ ìƒìœ„ 800ê°œ íŠ¹ì§•ì˜ ì¸ë±ìŠ¤ë¥¼ ì„ íƒ\n",
    "NUM_TOP_FEATURES = 800\n",
    "feature_importances = fs_model.feature_importances_\n",
    "top_feature_indices = np.argsort(feature_importances)[-NUM_TOP_FEATURES:]\n",
    "\n",
    "# 4. ì„ íƒëœ íŠ¹ì§•ìœ¼ë¡œ ìƒˆë¡œìš´ 'ìŠ¬ë¦¼' ë°ì´í„°ì…‹ ìƒì„±\n",
    "print(f\"ì¤‘ìš”ë„ ìƒìœ„ {NUM_TOP_FEATURES}ê°œì˜ íŠ¹ì§•ë§Œ ì„ íƒí•˜ì—¬ ìƒˆë¡œìš´ ë°ì´í„°ì…‹ì„ ìƒì„±í•©ë‹ˆë‹¤.\")\n",
    "X_train_slim = X_train_clean[:, top_feature_indices]\n",
    "X_test_slim = X_test_final[:, top_feature_indices]\n",
    "\n",
    "print(f\"íŠ¹ì§• ì„ íƒ ì™„ë£Œ! ìƒˆë¡œìš´ í›ˆë ¨ ë°ì´í„° shape: {X_train_slim.shape}\")\n",
    "\n",
    "# ë©”ëª¨ë¦¬ ì •ë¦¬\n",
    "del X_train_sample, y_train_sample, fs_model, feature_importances\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "# --- ì„ íƒëœ íŠ¹ì§•(X_train_slim)ìœ¼ë¡œ 5-Fold êµì°¨ê²€ì¦ ì§„í–‰ ---\n",
    "print(\"\\nì„ íƒëœ íŠ¹ì§•ìœ¼ë¡œ ìµœì¢… ëª¨ë¸ í•™ìŠµì„ ì‹œì‘í•©ë‹ˆë‹¤...\")\n",
    "sgkf = StratifiedGroupKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "lgb_oof_preds = np.zeros(len(X_train_slim))\n",
    "lgb_test_preds_list = []\n",
    "lgb_models = []\n",
    "\n",
    "lgb_params = {'objective': 'binary', 'metric': 'auc', 'boosting_type': 'gbdt',\n",
    "              'n_estimators': 2000, 'learning_rate': 0.05, 'num_leaves': 41,\n",
    "              'max_depth': 6, 'seed': 42, 'n_jobs': 16, 'verbose': -1, 'colsample_bytree': 0.8}\n",
    "\n",
    "# groups_cleanë„ slim ë°ì´í„°ì…‹ì— ë§ê²Œ ì¸ë±ì‹±í•´ì•¼ í•©ë‹ˆë‹¤. (ì´ ë¶€ë¶„ì€ ë™ì¼)\n",
    "for fold, (train_idx, val_idx) in enumerate(sgkf.split(X_train_slim, y_train_clean, groups_clean)):\n",
    "    print(f\"--- Fold {fold+1} (LGBM) ---\")\n",
    "    X_train, y_train = X_train_slim[train_idx], y_train_clean[train_idx]\n",
    "    X_val, y_val = X_train_slim[val_idx], y_train_clean[val_idx]\n",
    "    \n",
    "    lgb_model = lgb.LGBMClassifier(**lgb_params)\n",
    "    lgb_model.fit(X_train, y_train, eval_set=[(X_val, y_val)], callbacks=[lgb.early_stopping(100, verbose=False)])\n",
    "    \n",
    "    lgb_oof_preds[val_idx] = lgb_model.predict_proba(X_val)[:, 1]\n",
    "    # í…ŒìŠ¤íŠ¸ ë°ì´í„° ì˜ˆì¸¡ë„ slim ë²„ì „ìœ¼ë¡œ í•´ì•¼ í•¨\n",
    "    lgb_test_preds_list.append(lgb_model.predict_proba(X_test_slim)[:, 1])\n",
    "    lgb_models.append(lgb_model)\n",
    "    \n",
    "    del X_train, y_train, X_val, y_val, lgb_model\n",
    "    gc.collect()\n",
    "\n",
    "lgb_oof_auc = roc_auc_score(y_train_clean, lgb_oof_preds)\n",
    "print(f\"ğŸ† LightGBM ìµœì¢… OOF AUC: {lgb_oof_auc:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40379496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 4-2ë‹¨ê³„: XGBoost ëª¨ë¸ í•™ìŠµ ì‹œì‘ ---\n",
      "--- Fold 1 (XGBoost) ---\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m     14\u001b[39m X_val, y_val = X_train_clean[val_idx], y_train_clean[val_idx]\n\u001b[32m     15\u001b[39m xgb_model = xgb.XGBClassifier(**xgb_params, n_estimators=\u001b[32m2000\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m \u001b[43mxgb_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_set\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     17\u001b[39m xgb_oof_preds[val_idx] = xgb_model.predict_proba(X_val)[:, \u001b[32m1\u001b[39m]\n\u001b[32m     18\u001b[39m xgb_test_preds_list.append(xgb_model.predict_proba(X_test_final)[:, \u001b[32m1\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\develop\\deep_learning\\DACON\\venv\\Lib\\site-packages\\xgboost\\core.py:729\u001b[39m, in \u001b[36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    727\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig.parameters, args):\n\u001b[32m    728\u001b[39m     kwargs[k] = arg\n\u001b[32m--> \u001b[39m\u001b[32m729\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\develop\\deep_learning\\DACON\\venv\\Lib\\site-packages\\xgboost\\sklearn.py:1682\u001b[39m, in \u001b[36mXGBClassifier.fit\u001b[39m\u001b[34m(self, X, y, sample_weight, base_margin, eval_set, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights)\u001b[39m\n\u001b[32m   1660\u001b[39m model, metric, params, feature_weights = \u001b[38;5;28mself\u001b[39m._configure_fit(\n\u001b[32m   1661\u001b[39m     xgb_model, params, feature_weights\n\u001b[32m   1662\u001b[39m )\n\u001b[32m   1663\u001b[39m train_dmatrix, evals = _wrap_evaluation_matrices(\n\u001b[32m   1664\u001b[39m     missing=\u001b[38;5;28mself\u001b[39m.missing,\n\u001b[32m   1665\u001b[39m     X=X,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1679\u001b[39m     feature_types=\u001b[38;5;28mself\u001b[39m.feature_types,\n\u001b[32m   1680\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1682\u001b[39m \u001b[38;5;28mself\u001b[39m._Booster = \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1683\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1684\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_dmatrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1685\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_num_boosting_rounds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1686\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevals\u001b[49m\u001b[43m=\u001b[49m\u001b[43mevals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1687\u001b[39m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1688\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevals_result\u001b[49m\u001b[43m=\u001b[49m\u001b[43mevals_result\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1689\u001b[39m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m=\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1690\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcustom_metric\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1691\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1692\u001b[39m \u001b[43m    \u001b[49m\u001b[43mxgb_model\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1693\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1694\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1696\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m.objective):\n\u001b[32m   1697\u001b[39m     \u001b[38;5;28mself\u001b[39m.objective = params[\u001b[33m\"\u001b[39m\u001b[33mobjective\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\develop\\deep_learning\\DACON\\venv\\Lib\\site-packages\\xgboost\\core.py:729\u001b[39m, in \u001b[36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    727\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig.parameters, args):\n\u001b[32m    728\u001b[39m     kwargs[k] = arg\n\u001b[32m--> \u001b[39m\u001b[32m729\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\develop\\deep_learning\\DACON\\venv\\Lib\\site-packages\\xgboost\\training.py:183\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(params, dtrain, num_boost_round, evals, obj, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[39m\n\u001b[32m    181\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cb_container.before_iteration(bst, i, dtrain, evals):\n\u001b[32m    182\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m183\u001b[39m \u001b[43mbst\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miteration\u001b[49m\u001b[43m=\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfobj\u001b[49m\u001b[43m=\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    184\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cb_container.after_iteration(bst, i, dtrain, evals):\n\u001b[32m    185\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\develop\\deep_learning\\DACON\\venv\\Lib\\site-packages\\xgboost\\core.py:2247\u001b[39m, in \u001b[36mBooster.update\u001b[39m\u001b[34m(self, dtrain, iteration, fobj)\u001b[39m\n\u001b[32m   2243\u001b[39m \u001b[38;5;28mself\u001b[39m._assign_dmatrix_features(dtrain)\n\u001b[32m   2245\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   2246\u001b[39m     _check_call(\n\u001b[32m-> \u001b[39m\u001b[32m2247\u001b[39m         \u001b[43m_LIB\u001b[49m\u001b[43m.\u001b[49m\u001b[43mXGBoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2248\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctypes\u001b[49m\u001b[43m.\u001b[49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle\u001b[49m\n\u001b[32m   2249\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2250\u001b[39m     )\n\u001b[32m   2251\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2252\u001b[39m     pred = \u001b[38;5;28mself\u001b[39m.predict(dtrain, output_margin=\u001b[38;5;28;01mTrue\u001b[39;00m, training=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "print(\"--- 4-2ë‹¨ê³„: XGBoost ëª¨ë¸ í•™ìŠµ ì‹œì‘ ---\")\n",
    "\n",
    "xgb_oof_preds = np.zeros(len(X_train_clean))\n",
    "xgb_test_preds_list = []\n",
    "xgb_models = []\n",
    "\n",
    "xgb_params = {'objective': 'binary:logistic', 'eval_metric': 'auc', 'eta': 0.05,\n",
    "              'max_depth': 5, 'subsample': 0.7, 'colsample_bytree': 0.8,\n",
    "              'device': 'cuda', 'tree_method': 'hist', 'random_state': 42}\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(sgkf.split(X_train_clean, y_train_clean, groups_clean)):\n",
    "    print(f\"--- Fold {fold+1} (XGBoost) ---\")\n",
    "    X_train, y_train = X_train_clean[train_idx], y_train_clean[train_idx]\n",
    "    X_val, y_val = X_train_clean[val_idx], y_train_clean[val_idx]\n",
    "    xgb_model = xgb.XGBClassifier(**xgb_params, n_estimators=2000)\n",
    "    xgb_model.fit(X_train, y_train, eval_set=[(X_val, y_val)], verbose=0)\n",
    "    xgb_oof_preds[val_idx] = xgb_model.predict_proba(X_val)[:, 1]\n",
    "    xgb_test_preds_list.append(xgb_model.predict_proba(X_test_final)[:, 1])\n",
    "    xgb_models.append(xgb_model)\n",
    "\n",
    "xgb_oof_auc = roc_auc_score(y_train_clean, xgb_oof_preds)\n",
    "print(f\"ğŸ† XGBoost ìµœì¢… OOF AUC: {xgb_oof_auc:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6da5bde9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 5ë‹¨ê³„: ìµœì¢… ì œì¶œ (LGBM ë‹¨ì¼ ëª¨ë¸) ---\n",
      "LightGBM ë‹¨ì¼ ëª¨ë¸ì˜ ì˜ˆì¸¡ê°’ìœ¼ë¡œ ì œì¶œ íŒŒì¼ì„ ìƒì„±í•©ë‹ˆë‹¤.\n",
      "ğŸ‰ ìµœì¢… ì œì¶œ íŒŒì¼ ìƒì„± ì™„ë£Œ: submission_lgbm_only_20250715_0916.csv\n"
     ]
    }
   ],
   "source": [
    "print(\"--- 5ë‹¨ê³„: ìµœì¢… ì œì¶œ (LGBM ë‹¨ì¼ ëª¨ë¸) ---\")\n",
    "\n",
    "# LightGBM 5-Fold ëª¨ë¸ë“¤ì˜ í…ŒìŠ¤íŠ¸ ë°ì´í„° ì˜ˆì¸¡ê°’ í‰ê·  ê³„ì‚°\n",
    "lgb_final_preds = np.mean(lgb_test_preds_list, axis=0)\n",
    "print(\"LightGBM ë‹¨ì¼ ëª¨ë¸ì˜ ì˜ˆì¸¡ê°’ìœ¼ë¡œ ì œì¶œ íŒŒì¼ì„ ìƒì„±í•©ë‹ˆë‹¤.\")\n",
    "\n",
    "# ì œì¶œ íŒŒì¼ ìƒì„±\n",
    "sample_submission['generated'] = lgb_final_preds\n",
    "\n",
    "# íŒŒì¼ ì´ë¦„ì— lgbm_onlyë¥¼ ì¶”ê°€í•˜ì—¬ êµ¬ë¶„\n",
    "submission_filename = f\"submission_lgbm_only_{pd.Timestamp.now().strftime('%Y%m%d_%H%M')}.csv\"\n",
    "sample_submission.to_csv(submission_filename, index=False)\n",
    "sample_submission.to_csv(\"submission.csv\", index=False) # ê¸°ë³¸ íŒŒì¼ë„ ìƒì„±\n",
    "\n",
    "print(f\"ğŸ‰ ìµœì¢… ì œì¶œ íŒŒì¼ ìƒì„± ì™„ë£Œ: {submission_filename}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
